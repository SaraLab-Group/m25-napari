{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualizer import calibration\n",
    "import visual\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.io.collection import alphanumeric_key\n",
    "from dask import delayed\n",
    "from glob import glob\n",
    "import dask.array as da\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import napari\n",
    "from napari import Viewer\n",
    "import os\n",
    "\n",
    "from skimage.registration import phase_cross_correlation\n",
    "import cv2 as cv\n",
    "from skimage import io\n",
    "\n",
    "import cupy as cp \n",
    "import imagej\n",
    "\n",
    "%gui qt \n",
    "%matplotlib inline\n",
    "plt.style.use('dark_background')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_folder = r'E:\\Ed\\Data\\20220324_drosophila_egg\\20220324_M25_head-3_WL'\n",
    "# main_folder = r'E:\\Ed\\Data\\test_flies\\20220322_M25_larvae_05'\n",
    "main_folder = r'E:\\Ed\\Data\\20220324_drosophila_egg\\20220324_M25_PSF1'\n",
    "\n",
    "# folder = r'E:\\Ed\\PSF\\20220124_M25_allcameras\\CAM_Z2'\n",
    "# file_extension = folder + '/' + '*.raw'\n",
    "folder_names = sorted(glob(main_folder + '/CAM*/'), key=alphanumeric_key)\n",
    "offsets_file = os.path.join(main_folder,\"offsets.csv\")\n",
    "\n",
    "# file_names = sorted(glob(file_extension),key=alphanumeric_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5626666666666666e-07\n",
      "0.341296928327645\n",
      "25.000000000000004\n"
     ]
    }
   ],
   "source": [
    "#Scope Parameters\n",
    "FOV = 50e-6\n",
    "cam_px = 5.86e-6\n",
    "totalmag = 37.5\n",
    "px_size_img = cam_px/totalmag\n",
    "zstep = 2e-6\n",
    "# z_scale = zstep/px_size_img\n",
    "z_scale = FOV/zstep\n",
    "\n",
    "print(px_size_img)\n",
    "print(zstep/cam_px)\n",
    "print(z_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8bit\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    stack= calibration.load_dataset(main_folder,'uint8')\n",
    "    print(\"8bit\")\n",
    "except: \n",
    "    print(\"16bit\")\n",
    "    stack = calibration.load_dataset(main_folder,'uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load offsets from desired folder \n",
    "# main_folder = r'E:\\Ed\\Data\\20220324_drosophila_egg\\20220324_M25_PSF2-16bit'\n",
    "main_folder = r'E:\\Ed\\Data\\20220324_drosophila_egg\\20220324_M25_PSF1'\n",
    "offsets_file_load = os.path.join(main_folder,\"offsets.csv\")\n",
    "with open(offsets_file_load) as file_name:\n",
    "    offsets = np.loadtxt(file_name, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# px_depth = 'uint16'\n",
    "# # px_depth = 'uint8'\n",
    "\n",
    "# raw_M25_volume = [calibration.dask_raw_ds(fd,px_depth) for fd in folder_names]\n",
    "# stack = da.concatenate(raw_M25_volume, axis=1)\n",
    "# stack_max_projection= np.array([ da.max(stack[:,i,:,:],axis=0) for i in range(stack.shape[1])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'stack' at 0x1aaa971c6a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback BaseAsyncIOLoop._handle_events(8160, 1)\n",
      "handle: <Handle BaseAsyncIOLoop._handle_events(8160, 1)>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Callisto\\Anaconda3\\envs\\napari-pymmcore\\lib\\asyncio\\events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Callisto\\Anaconda3\\envs\\napari-pymmcore\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 189, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"C:\\Users\\Callisto\\Anaconda3\\envs\\napari-pymmcore\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 452, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"C:\\Users\\Callisto\\Anaconda3\\envs\\napari-pymmcore\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 481, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"C:\\Users\\Callisto\\Anaconda3\\envs\\napari-pymmcore\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 431, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"C:\\Users\\Callisto\\Anaconda3\\envs\\napari-pymmcore\\lib\\site-packages\\jupyter_client\\threaded.py\", line 121, in _handle_recv\n",
      "    msg_list = self.ioloop._asyncio_event_loop.run_until_complete(get_msg(future_msg))\n",
      "  File \"C:\\Users\\Callisto\\Anaconda3\\envs\\napari-pymmcore\\lib\\asyncio\\base_events.py\", line 592, in run_until_complete\n",
      "    self._check_running()\n",
      "  File \"C:\\Users\\Callisto\\Anaconda3\\envs\\napari-pymmcore\\lib\\asyncio\\base_events.py\", line 554, in _check_running\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Cannot run the event loop while another loop is running\n"
     ]
    }
   ],
   "source": [
    "viewer=napari.Viewer()\n",
    "viewer.add_image(stack,scale=[z_scale,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Calibration from Bead's Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our own shifted datset\n",
    "with cp.cuda.Device(0):\n",
    "    # test = stack[:,11:15,:,:]\n",
    "    test = stack\n",
    "    t,c,h,w  = test.shape\n",
    "    np_mip =[]\n",
    "    for i in range(c):\n",
    "        cp_stack = cp.array(test[:,i,:,:])\n",
    "        cp_mip = cp.max(cp_stack, axis=0)\n",
    "        np_mip.append(cp.asnumpy(cp_mip))\n",
    "        cp_mip = None\n",
    "        cp_stack=None\n",
    "    np_mip = np.array(np_mip)\n",
    "    np_mip = np.expand_dims(np_mip,axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'mip' at 0x1e3e72a44c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the maximum intensity projection\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(np_mip, name='mip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.          12.         292.48246486 393.88598238]\n",
      " [  0.          12.         292.48246486 397.39475431]\n",
      " [  0.          12.         295.99123679 397.39475431]\n",
      " [  0.          12.         295.99123679 393.88598238]]\n",
      "[[292 394]\n",
      " [296 397]]\n",
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "#Go to napari and make a square for alignment\n",
    "crop_region =viewer.layers['Shapes'].data[0]\n",
    "template = calibration.create_box_ndarray(crop_region)\n",
    "template_box = template[0:4,2:4]\n",
    "print(crop_region)\n",
    "print(template_box)\n",
    "print(template_box.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'crop' at 0x1e3a58b6c10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since OpenCV Match Template takes in uint8 || float32. We can change from uint16 to uint8 easily\n",
    "np_mip_8bit =visual.im_bit_convert(np_mip,bit=8)\n",
    "min_val, max_val = template_box\n",
    "t,c = template[0,0:2]\n",
    "crop_img = np_mip_8bit[t,c, min_val[0]:max_val[0],min_val[1]:max_val[1]]\n",
    "viewer.add_image(crop_img,name='crop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 960)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_mip_8bit[0,i,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 4\n",
      "[(0, 0), (21, 23), (6, -148), (5, -139), (42, -167), (22, -64), (47, -47), (51, -45), (37, -61), (92, -88), (72, 22), (51, 10), (69, 7), (98, -10), (95, -21), (34, 38), (98, -19), (85, 30), (61, -50), (105, -46), (101, 39), (99, 19), (106, -29), (99, -43), (129, -25)]\n"
     ]
    }
   ],
   "source": [
    "coord =[]\n",
    "w,h = template.shape  \n",
    "methods = 'cv.TM_CCOEFF'\n",
    "print(w,h)\n",
    "t,c,h,w = np_mip_8bit.shape\n",
    "\n",
    "for i in range(c):\n",
    "    method = eval(methods) # This method parses expression and runs ()\n",
    "    # Apply template Matching\n",
    "    # Slide through image and compare template patches.\n",
    "    # Comparison of best matches is foudn as global minn in SQDIFF or max in CCORR or CCOEF.\n",
    "    res = cv.matchTemplate(np_mip_8bit[0,i,:,:],crop_img,method)\n",
    "    min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
    "    # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    "    if method in [cv.TM_SQDIFF, cv.TM_SQDIFF_NORMED]:\n",
    "        top_left = min_loc\n",
    "    else:\n",
    "        top_left = max_loc\n",
    "        \n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "    #Output would contain the Top left corner and bottom right in case of need to use this rectangle\n",
    "    coord.append(((top_left[1],top_left[0]),(bottom_right[1],bottom_right[0])))\n",
    "\n",
    "#For the bead calibration we only use the TL points for alignment\n",
    "TL_coords = np.array(coord)\n",
    "TL_coords= TL_coords[0:25,0]\n",
    "\n",
    "#Coordinates need to then be subtracted to the reference frame (i.e t,c for which rectangle was drawn)\n",
    "res = []\n",
    "ref_cam_index = 0\n",
    "# diff =[]\n",
    "for i,coordinate in enumerate(TL_coords):\n",
    "    val = tuple(map(lambda i, j: i - j, TL_coords[ref_cam_index],coordinate))\n",
    "    res.append(val)\n",
    "    #If previous values available we can find teh difference between them\n",
    "    # diff.append(tuple(map(lambda i, j: i + j, val,shift_stack_coord[i])))\n",
    "# print(diff)\n",
    "print(res)\n",
    "# print(shift_stack_coord)\n",
    "offset_coordinates = np.array(res)\n",
    "\n",
    "#Save the Offsets in the folder\n",
    "np.savetxt(offsets_file, offset_coordinates, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 3)\n",
      "(385, 25, 600, 960)\n"
     ]
    }
   ],
   "source": [
    "from cupyx.scipy.ndimage import shift\n",
    "import cupy as cp\n",
    "# Generate our own shifted datset\n",
    "with cp.cuda.Device(0):\n",
    "    stack_aligned = []\n",
    "    t,c,h,w = stack.shape\n",
    "    shift_stack_cam = cp.zeros((c,h,w))\n",
    "    columns = cp.zeros((offset_coordinates.shape[0],1))\n",
    "    shift_stack_coord = cp.hstack((columns,offset_coordinates))\n",
    "    print(shift_stack_coord.shape)\n",
    "    print(stack.shape)\n",
    "    for i in range(c):\n",
    "        cp_stack = cp.array(stack[:,i,:,:])\n",
    "        shift_stack_cam= shift(cp_stack,shift_stack_coord[i])\n",
    "        stack_aligned.append(cp.asnumpy(shift_stack_cam))\n",
    "        cp_stack = None\n",
    "    stack_aligned = np.array(stack_aligned)\n",
    "stack_aligned =  np.moveaxis(stack_aligned,0,1)\n",
    "\n",
    "#Convert to Dask Array\n",
    "stack_aligned = da.from_array(stack_aligned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(385, 25, 600, 960)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stack_aligned =  np.moveaxis(stack_aligned,0,1)\n",
    "stack_aligned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'test [1]' at 0x1e51ea575e0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(stack_aligned, name='test',scale = [z_scale,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align Datasets with Known Offsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 3)\n",
      "(400, 25, 600, 960)\n"
     ]
    }
   ],
   "source": [
    "from cupyx.scipy.ndimage import shift\n",
    "import cupy as cp\n",
    "# Generate our own shifted datset\n",
    "\n",
    "offset_coordinates = offsets\n",
    "with cp.cuda.Device(0):\n",
    "    stack_aligned = []\n",
    "    t,c,h,w = stack.shape\n",
    "    shift_stack_cam = cp.zeros((c,h,w))\n",
    "    columns = cp.zeros((offset_coordinates.shape[0],1))\n",
    "    shift_stack_coord = cp.hstack((columns,offset_coordinates))\n",
    "    print(shift_stack_coord.shape)\n",
    "    print(stack.shape)\n",
    "    for i in range(c):\n",
    "        cp_stack = cp.array(stack[:,i,:,:])\n",
    "        shift_stack_cam= shift(cp_stack,shift_stack_coord[i])\n",
    "        stack_aligned.append(cp.asnumpy(shift_stack_cam))\n",
    "        cp_stack = None\n",
    "    stack_aligned = np.array(stack_aligned)\n",
    "stack_aligned =  np.moveaxis(stack_aligned,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask.array<array, shape=(400, 25, 600, 960), dtype=uint16, chunksize=(100, 25, 120, 120), chunktype=numpy.ndarray>\n"
     ]
    }
   ],
   "source": [
    "#Convert numpy to dask?\n",
    "da_stack_align = da.from_array(stack_aligned)\n",
    "print(da_stack_align)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.86\n",
      "0.341296928327645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-21:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Callisto\\Anaconda3\\envs\\napari-pymmcore\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Callisto\\Anaconda3\\envs\\napari-pymmcore\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\callisto\\documents\\edhirata\\tutorials\\m25_napari\\src\\visualizer\\_app.py\", line 82, in client_thread\n",
      "    s.connect((self.HOST, self.PORT))\n",
      "ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback BaseAsyncIOLoop._handle_events(9360, 1)\n",
      "handle: <Handle BaseAsyncIOLoop._handle_events(9360, 1)>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Callisto\\Anaconda3\\envs\\napari-pymmcore\\lib\\asyncio\\events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Callisto\\Anaconda3\\envs\\napari-pymmcore\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 189, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"C:\\Users\\Callisto\\Anaconda3\\envs\\napari-pymmcore\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 452, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"C:\\Users\\Callisto\\Anaconda3\\envs\\napari-pymmcore\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 481, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"C:\\Users\\Callisto\\Anaconda3\\envs\\napari-pymmcore\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 431, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"C:\\Users\\Callisto\\Anaconda3\\envs\\napari-pymmcore\\lib\\site-packages\\jupyter_client\\threaded.py\", line 121, in _handle_recv\n",
      "    msg_list = self.ioloop._asyncio_event_loop.run_until_complete(get_msg(future_msg))\n",
      "  File \"C:\\Users\\Callisto\\Anaconda3\\envs\\napari-pymmcore\\lib\\asyncio\\base_events.py\", line 592, in run_until_complete\n",
      "    self._check_running()\n",
      "  File \"C:\\Users\\Callisto\\Anaconda3\\envs\\napari-pymmcore\\lib\\asyncio\\base_events.py\", line 554, in _check_running\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Cannot run the event loop while another loop is running\n"
     ]
    }
   ],
   "source": [
    "viewer= napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'dask_align [1]' at 0x1aab10a8d90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(da_stack_align, name='dask_align',scale=[zstep/px_size,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image J Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def start_imagej():\n",
    "    global ij\n",
    "    ij = imagej.init(r'C:\\Users\\Callisto\\Documents\\edhirata\\software\\Fiji.app',headless=False)\n",
    "    ij.ui().showUI()\n",
    "    print(ij.getVersion())\n",
    "\n",
    "QtCore.QTimer.singleShot(0, start_imagej)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def start_imagej():\n",
    "#     global ij\n",
    "#     ij = imagej.init(headless=False)\n",
    "#     ij.ui().showUI()\n",
    "#     print(ij.getVersion())\n",
    "\n",
    "# QtCore.QTimer.singleShot(0, start_imagej)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align the files\n",
    "ij_stack2  = ij.py.to_java(np.array(stack_aligned,dtype='uint16'))\n",
    "ij.ui().show('aligned_stack', ij_stack2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_volume_cp.shape\n",
    "cuda_mem_info()\n",
    "cuda_clear()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f50b1b136b84281a212ea9a5d6d43809733f4203708b5ddd6edbf2eda8994f89"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('napari-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
